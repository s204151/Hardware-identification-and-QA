{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:w6z8xn09) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='1.131 MB of 1.131 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c261940697e41dcbf8cdd7165b320b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">fragrant-cosmos-3</strong>: <a href=\"https://wandb.ai/otovo-dtu-qa/test-project/runs/w6z8xn09\" target=\"_blank\">https://wandb.ai/otovo-dtu-qa/test-project/runs/w6z8xn09</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20220602_001231-w6z8xn09\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:w6z8xn09). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.17"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\DTU-D\\4\\Fagprojekt\\Hardware-identification-and-QA\\Data exploration code\\wandb\\run-20220602_002245-wef1diy5</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/otovo-dtu-qa/test-project/runs/wef1diy5\" target=\"_blank\">jumping-universe-2</a></strong> to <a href=\"https://wandb.ai/otovo-dtu-qa/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import easyocr\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"test-project\", entity=\"otovo-dtu-qa\")\n",
    "\n",
    "rootPath = \"D:/DTU-D/4/Fagprojekt/Data\"\n",
    "csvName = \"labels.csv\"\n",
    "csvName2 = \"labels2.csv\"\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "data = pd.concat([\n",
    "    pd.read_csv(os.path.join(rootPath,csvName)),\n",
    "    pd.read_csv(os.path.join(rootPath,csvName2))\n",
    "])\n",
    "batch = 1\n",
    "# data.drop(data.index[[1711]], inplace=True) #GIF\n",
    "data.drop(data.index[[3033,3034,3035]], inplace=True) #Corrupted pictures\n",
    "rows = data.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<wandb.sdk.wandb_artifacts.Artifact at 0x1cd09830520>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact = wandb.Artifact('test-dataset', type='dataset')\n",
    "\n",
    "# Add a file to the artifact's contents\n",
    "artifact.add_file(\"C:/Users/Damho/Desktop/Otovo_Example_Censored.jpg\")\n",
    "\n",
    "# Save the artifact version to W&B and mark it as the output of this run\n",
    "run.log_artifact(artifact)\n",
    "# wandb.log_artifact(\"C:/Users/Damho/Desktop/Otovo_Example_Censored.jpg\", name='test_artifact', type='my_dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128\n",
    "}\n",
    "\n",
    "# wandb.log({\"loss\": 0.5})\n",
    "wandb.log({'accuracy': 0.7, 'loss': 0.4})\n",
    "\n",
    "image = wandb.Image(\"C:/Users/Damho/Desktop/Otovo_Example_Censored.jpg\", caption=\"Input image\")\n",
    "wandb.log({\"examples\": image})\n",
    "\n",
    "# # Optional\n",
    "# wandb.watch(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3495 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ca2d767e7c14e1b8516e3b91c11d833"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Damho\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2896: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_126472/471180766.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrootPath\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadtext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparagraph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m     \u001B[0mresults\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\easyocr\\easyocr.py\u001B[0m in \u001B[0;36mreadtext\u001B[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, output_format)\u001B[0m\n\u001B[0;32m    391\u001B[0m         \u001B[1;31m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m         \u001B[0mhorizontal_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfree_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhorizontal_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfree_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 393\u001B[1;33m         result = self.recognize(img_cv_grey, horizontal_list, free_list,\\\n\u001B[0m\u001B[0;32m    394\u001B[0m                                 \u001B[0mdecoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbeamWidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m                                 \u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallowlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblocklist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdetail\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrotation_info\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\easyocr\\easyocr.py\u001B[0m in \u001B[0;36mrecognize\u001B[1;34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001B[0m\n\u001B[0;32m    323\u001B[0m                 \u001B[0mh_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mbbox\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m                 \u001B[0mf_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 325\u001B[1;33m                 \u001B[0mimage_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_width\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_image_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_cv_grey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_height\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimgH\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    326\u001B[0m                 result0 = get_text(self.character, imgH, int(max_width), self.recognizer, self.converter, image_list,\\\n\u001B[0;32m    327\u001B[0m                               \u001B[0mignore_char\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbeamWidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontrast_ths\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0madjust_contrast\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilter_ths\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\easyocr\\utils.py\u001B[0m in \u001B[0;36mget_image_list\u001B[1;34m(horizontal_list, free_list, img, model_height, sort_output)\u001B[0m\n\u001B[0;32m    538\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_image_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhorizontal_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfree_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_height\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msort_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    539\u001B[0m     \u001B[0mimage_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 540\u001B[1;33m     \u001B[0mmaximum_y\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmaximum_x\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    541\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    542\u001B[0m     \u001B[0mmax_ratio_hori\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_ratio_free\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "ground_truth = []\n",
    "correctIn = 0\n",
    "for i in tqdm(range(rows)):\n",
    "    # Primitive attempt at batching\n",
    "    if i % batch == 0:\n",
    "        del reader\n",
    "        torch.cuda.empty_cache()\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    image_path = data.iloc[i]['image_path'].lower()\n",
    "    if image_path.endswith(\"gif\") or image_path.endswith(\"pdf\"):\n",
    "        continue\n",
    "    # The replaced letters are NOT the same. There is a mismatch between the csv file and the actual picture name\n",
    "    if \"Ã¤\" in image_path:\n",
    "        image_path = image_path.replace(\"Ã¤\", \"aÌˆ\")\n",
    "    if \"Ã¥\" in image_path:\n",
    "        image_path = image_path.replace(\"Ã¥\", \"aÌŠ\")\n",
    "    if \"Ã¶\" in image_path:\n",
    "        image_path = image_path.replace(\"Ã¶\", \"oÌˆ\")\n",
    "    path = os.path.join(rootPath,image_path)\n",
    "\n",
    "    result = reader.readtext(path, paragraph=True)\n",
    "    results.append(result)\n",
    "\n",
    "    y = data.iloc[i]['meter_number']\n",
    "    ground_truth.append(y)\n",
    "    for j in range(len(result)):\n",
    "        if y in result[j]:\n",
    "            correctIn += 1\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_126472/2058413582.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mreader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0measyocr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'en'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadtext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparagraph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;31m# cv2.imdecode(np.fromfile(path, np.uint8), cv2.IMREAD_UNCHANGED).shape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\easyocr\\easyocr.py\u001B[0m in \u001B[0;36mreadtext\u001B[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, output_format)\u001B[0m\n\u001B[0;32m    391\u001B[0m         \u001B[1;31m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m         \u001B[0mhorizontal_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfree_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhorizontal_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfree_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 393\u001B[1;33m         result = self.recognize(img_cv_grey, horizontal_list, free_list,\\\n\u001B[0m\u001B[0;32m    394\u001B[0m                                 \u001B[0mdecoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbeamWidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m                                 \u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallowlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblocklist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdetail\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrotation_info\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\easyocr\\easyocr.py\u001B[0m in \u001B[0;36mrecognize\u001B[1;34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001B[0m\n\u001B[0;32m    323\u001B[0m                 \u001B[0mh_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mbbox\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m                 \u001B[0mf_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 325\u001B[1;33m                 \u001B[0mimage_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_width\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_image_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_cv_grey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_height\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimgH\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    326\u001B[0m                 result0 = get_text(self.character, imgH, int(max_width), self.recognizer, self.converter, image_list,\\\n\u001B[0;32m    327\u001B[0m                               \u001B[0mignore_char\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbeamWidth\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontrast_ths\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0madjust_contrast\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfilter_ths\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\easyocr\\utils.py\u001B[0m in \u001B[0;36mget_image_list\u001B[1;34m(horizontal_list, free_list, img, model_height, sort_output)\u001B[0m\n\u001B[0;32m    538\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_image_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhorizontal_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfree_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_height\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msort_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    539\u001B[0m     \u001B[0mimage_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 540\u001B[1;33m     \u001B[0mmaximum_y\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmaximum_x\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    541\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    542\u001B[0m     \u001B[0mmax_ratio_hori\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_ratio_free\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "result = reader.readtext(path, paragraph=True)\n",
    "# cv2.imdecode(np.fromfile(path, np.uint8), cv2.IMREAD_UNCHANGED).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"pretrained accuracy: {(correctIn/len(data.project_id.unique()))*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# np.savez(\"Variables_results_08_04_2022_detailsOn_paragraphTrue\",\n",
    "#          correctIn=correctIn,\n",
    "#          ground_truth=ground_truth\n",
    "#          results=np.array(results,dtype=object))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Rename files\n",
    "# tochange = [29,45,133,135,136,180,186,203,303,347,349,369,379,429,514,562,566,644,645,713,821,946,1008,1073,1074,1087,1211,1212,1233,1325,1558,1568,1573,1574,1577,1611,1743,1900,372,908,958,959,992,993,1061,1362,1651,1671,1675,1735]\n",
    "#\n",
    "# for i in tochange:\n",
    "#     image_path = data.iloc[i]['image_path']\n",
    "#     newName = os.path.join(rootPath,image_path.replace(\"Ã¥\",\"aa\").replace(\"Ã¸\",\"oo\").replace(\"Ã¦\",\"ae\"))\n",
    "#     oldFileName = os.listdir(os.path.join(rootPath,os.path.dirname(image_path)))[0]\n",
    "#     oldName = os.path.join(rootPath,os.path.dirname(image_path),oldFileName)\n",
    "#     os.rename(oldName,newName)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}